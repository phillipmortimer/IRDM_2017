\documentclass[english]{article}

%These tell TeX which packages to use.
\usepackage{algorithm,algpseudocode}
\usepackage{array,epsfig}
\usepackage{amsmath}
\newcommand{\Mod}[1]{\ (\text{mod}\ #1)}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsxtra}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage{listings}
\usepackage{matlab-prettifier}
\usepackage{scrextend}
\usepackage{mathtools,calc}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{amssymb}
\usepackage{subcaption}
\newcommand\hcancel[2][0.5pt]{%
  \ifmmode\sbox\CBox{$#2$}\else\sbox\CBox{#2}\fi%
  \makebox[0pt][l]{\usebox\CBox}%  
  \rule[0.5\ht\CBox-#1/2]{\wd\CBox}{#1}}
%\usepackage{kbordermatrix}


\usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
\definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
\definecolor{mylilas}{RGB}{170,55,241}


%Here I define some theorem styles and shortcut commands for symbols I use often
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem*{rmk}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem*{joke}{Joke}
\newtheorem{ex}{Example}
\newtheorem*{soln}{Solution}
\newtheorem{prop}{Proposition}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\lra}{\longrightarrow}
\newcommand{\ra}{\rightarrow}
\newcommand{\surj}{\twoheadrightarrow}
\newcommand{\graph}{\mathrm{graph}}
\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\Z}{\bb{Z}}
\newcommand{\Q}{\bb{Q}}
\newcommand{\R}{\bb{R}}
\newcommand{\C}{\bb{C}}
\newcommand{\N}{\bb{N}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\m}{\mathbf{m}}
\newcommand{\MM}{\mathscr{M}}
\newcommand{\HH}{\mathscr{H}}
\newcommand{\Om}{\Omega}
\newcommand{\Ho}{\in\HH(\Om)}
\newcommand{\bd}{\partial}
\newcommand{\del}{\partial}
\newcommand{\bardel}{\overline\partial}
\newcommand{\textdf}[1]{\textbf{\textsf{#1}}\index{#1}}
\newcommand{\img}{\mathrm{img}}
\newcommand{\ip}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\inter}[1]{\mathrm{int}{#1}}
\newcommand{\exter}[1]{\mathrm{ext}{#1}}
\newcommand{\cl}[1]{\mathrm{cl}{#1}}
\newcommand{\ds}{\displaystyle}
\newcommand{\vol}{\mathrm{vol}}
\newcommand{\cnt}{\mathrm{ct}}
\newcommand{\osc}{\mathrm{osc}}
\newcommand{\LL}{\mathbf{L}}
\newcommand{\UU}{\mathbf{U}}
\newcommand{\support}{\mathrm{support}}
\newcommand{\AND}{\;\wedge\;}
\newcommand{\OR}{\;\vee\;}
\newcommand{\Oset}{\varnothing}
\newcommand{\st}{\ni}
\newcommand{\wh}{\widehat}
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
   \def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

%Pagination stuff.
\setlength{\topmargin}{-.3 in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textheight}{9.in}
\setlength{\textwidth}{6.5in}

\newcommand{\pythonstyle}{\lstset{
language=Python,
keywordstyle=\color{blue},
stringstyle=\color{mylilas},
commentstyle=\color{mygreen},%
numbers=left,%
numberstyle={\tiny \color{black}},%
numbersep=9pt,
}}

\newcommand{\matlabstyle}{\lstset{language=Matlab,%
    %basicstyle=\color{red},
    breaklines=true,%
    morekeywords={matlab2tikz},
    keywordstyle=\color{blue},%
    morekeywords=[2]{1}, keywordstyle=[2]{\color{black}},
    identifierstyle=\color{black},%
    stringstyle=\color{mylilas},
    commentstyle=\color{mygreen},%
    showstringspaces=false,%without this there will be a symbol in the places where there is a space
    numbers=left,%
    numberstyle={\tiny \color{black}},% size of the numbers
    numbersep=9pt, % this defines how far the numbers are from the text
    emph=[1]{for,end,break},emphstyle=[1]\color{red}, %some words to emphasise
    %emph=[2]{word1,word2}, emphstyle=[2]{style},
}}

\begin{document}
\title{IRDM 2017 Project:\\Learning to Rank
}
\author{Group 42:\\
Ren Huang \\
Tom Jakab\\
Phillip Mortimer (16052718)}
\maketitle
\begin{abstract}
Required according to the problem sheet
\end{abstract}

\section{Introduction to the problem}

Introduction

\section{Related work}

Literature review?

\subsection{Learning to rank}

Before machine learning techniques became popular, numerous algorithms were developed to rank documents by their relevance to a particular query.  These algorithms are now surpassed in performance by machine learning approaches, but they can still be used as features for machine learning algorithms. 

An important non-probabilistic ranking algorithms is the term frequency - inverse document frequency (TF-IDF) weighting \cite{tfidf}.  The TF measures the frequency of occurrence of a given term in a document.  The IDF weights terms which occur in a small number of documents in a collection more highly, as infrequently occurring are likely to be more discriminative.  In vector space ranking, the TF-IDF weighting is extended by representing the queries and documents as a TF-IDF vectors.   A ranking score is computed based on the cosine similarity between the TF-IDF vector of the query and the TF-IDF vector of documents in the corpus.  Probabilistic models estimate the probability that a user will find a given document relevant to a query.  The Okapi BM25 ranking is the considered the benchmark model of this type.  It is derived from modelling the distribution of within-document frequencies of a relevant
term as a mixture of two Poisson distributions \cite{robertson1993okapi}.

These approaches are all essentially hand-designed algorithms which use only a small number of features.  Given training data of queries $q$, documents $d$ and a relevance or rank score $y$, we can \textit{learn} to predict $y$ for a new query-document pair.  Machine learning techniques to do this are generally categorized into three approaches: \textit{pointwise}, \textit{pairwise} and \textit{listwise}.  We review these approaches in the following sections.

\subsection{Pointwise methods}

In pointwise approaches the training data consists of triples $(\mathbf{q}, \mathbf{d}, y)$.  We train a ranking rule $h(\mathbf{w}, \phi (\mathbf{q}, \mathbf{d})) = y$, where $\phi$ is a mapping from query-document pairs to features and $\mathbf{w}$ is a vector of parameter weights.  Depending on how relevance is measured, this can be posed as a regression, classification or ordinal regression problem.  

PRank \cite{crammer2001pranking} (Perceptron Ranking) is an online ranking algorithm with an update rule motivated by the classic perceptron algorithm.  The relevance rank is considered to be an ordered set $\{1, 2, \ldots, k \}$.  The ranking rule maintains a vector $\mathbf{w}$ and a series of thresholds $b_1 \le b_2 \ldots b_{k-1} \le b_k = \infty$.  Given a new instance $x$, the predicted rank is defined to be the index of the first threshold $b_r$ for which $\mathbf{w}^T \mathbf{x} < b_r$.  During training an instance $\mathbf{x}_t$ is received and the estimated rank $\hat{y}_t$ is calculated.  If $\hat{y}_t \ne y_t$, then $\mathbf{w}$ and the thresholds $b_r$ are updated according to a perceptron-like algorithm.  

Pointwise approaches are widely used because of their simplicity and effectiveness.  However, a problem with pointwise methods is that the loss function used in training the model will be dominated by those queries which match a large number of documents.  The loss function also does not take into account the position of documents in the ranking list, which can lead to unimportant documents being given too much weight.

\subsection{Pairwise methods}

\subsection{Boosted regression}

\subsection{Deep learning in ranking systems}

For the 25\% bonus points

We survey some recent papers in this field and summarize their findings.

Deep convolutional networks have recently been applied to ranking text pairs by Severyn and Moschetti \cite{severyn2015learning}.  Their approach combines a simple pointwise ranking with a deep learning architecture to create a rich representation of query-document pairs.  First, a \textit{sentence model} uses a deep convolutional network to map queries or documents to an intermediate representation.  Second, a \textit{matching model} receives (query representation)-(document representation) pairs form the sentence model and learns the semantic matching between the corresponding input query-document pairs.  The matching model is also a  deep convolutional network.  The model was trained and tested on TREC microblogging datasets from 2011 and 2012, consisting of 16M tweets.  It achieved mean average precision performance on par with previous state-of-the-art, even though the model requires no manual feature engineering and minimal pre-processing.

\section{Dataset}

Description of the MSR dataset

\section{Experiments}

\subsection{The Statistics of the Dataset used}

\subsection{LambdaRank}

lambdarank

\subsection{RankNet}

ranknet

\subsection{Logistic regression classifier}

logistic regression

\subsection{Deep learning algorithm}

deep learning algo of our choice for 25\% bonus points \cite{gradclip}

\subsection{Metrics and Results}

\section{Analysis of results}

Analysis and evaluation

\subsection{Effect of parameter tuning on performance}

Effect of parameter tuning on performance

\subsection{Comparison of ranking algorithms}

Effect of parameter tuning on performance

\section{Discussion and limitations}

\section{Conclusion}

\newpage
\medskip

\bibliographystyle{unsrt}
\bibliography{IRDM_42}

\end{document}
